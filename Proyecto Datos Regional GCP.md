# üßæ Dise√±o de Plataforma de Datos Federada ‚Äì Google Cloud Platform

**Cliente**: Global Airline Group  
**Proyecto**: Plataforma Federada de Ingesta y Procesamiento de Datos  
**Consultor**: GCP ‚Äì Especialista en Arquitectura Cloud  
**Fecha**: Abril 2025

---

## 1. Introducci√≥n

Este documento presenta una soluci√≥n integral para construir una **plataforma de datos federada sobre Google Cloud Platform (GCP)**. Esta plataforma tiene como fin integrar y armonizar datos distribuidos geogr√°ficamente en distintas regiones y proyectos de GCP, permitiendo an√°lisis corporativos eficientes sobre indicadores clave como rentabilidad de rutas, eficiencia de combustible y satisfacci√≥n del cliente.

El objetivo es maximizar el **valor del dato** con una arquitectura escalable, gobernada y optimizada en costos, mediante servicios administrados de GCP, manteniendo alta disponibilidad y rendimiento en operaciones interregionales.

---

## 2. Problem√°tica

Actualmente, la organizaci√≥n enfrenta desaf√≠os t√©cnicos y operativos derivados de:

- **Silos de datos regionales** en m√∫ltiples proyectos GCP.
- **Esquemas inconsistentes** entre fuentes.
- Latencias elevadas en an√°lisis multi-regi√≥n.
- Costos crecientes por replicaci√≥n manual o soluciones ad-hoc.
- Falta de trazabilidad y unificaci√≥n del modelo de datos global.

---

## 3. Soluci√≥n Propuesta

Se propone una **arquitectura federada**, que permita ingestar, catalogar y procesar datos provenientes de BigQuery, Cloud Storage y CloudSQL en m√∫ltiples regiones de GCP, soportando flujos en **tiempo real y batch**, con herramientas nativas para gobernanza, eficiencia y an√°lisis avanzado.

---

### 3.1 Arquitectura General

La soluci√≥n incluye los siguientes componentes:

- **Cloud Pub/Sub**: canal de ingesti√≥n de eventos para procesamiento en tiempo real.
- **Cloud Functions**: disparadores ligeros para automatizaci√≥n basada en eventos.
- **Cloud Dataflow**: procesamiento ETL/ELT en batch y streaming.
- **Cloud Storage**: zona de datos crudos y almacenamiento intermedio.
- **BigQuery**: motor principal de almacenamiento anal√≠tico y federaci√≥n SQL.
- **BigQuery Omni** (opcional): consultas entre nubes o regiones remotas.
- **Dataplex**: gobernanza de datos y definici√≥n de zonas (raw, curado, anal√≠tico).
- **Data Catalog**: cat√°logo de metadatos y control de versiones de esquemas.
- **Looker / BI Engine**: visualizaci√≥n y an√°lisis de alto rendimiento.

---

### 3.2 Flujo de Datos

1. **Captura**
   - **CloudSQL (PostgreSQL)**: extra√≠do con Dataflow v√≠a JDBC.
   - **Cloud Storage**: eventos `OBJECT_FINALIZE` disparan funciones para ETL.
   - **BigQuery**: datasets regionales exportados con `EXPORT DATA`.

2. **Ingesta**
   - Archivos aterrizan en buckets por regi√≥n/domino (`raw/region_x/...`).
   - Cloud Dataflow mueve datos a BigQuery y los transforma.

3. **Procesamiento**
   - Transformaci√≥n y normalizaci√≥n de esquemas.
   - Aplicaci√≥n de reglas de negocio (e.g., conversi√≥n de monedas, unificaci√≥n de columnas).
   - Consolidaci√≥n en datasets curados listos para an√°lisis.

4. **Federaci√≥n y Consumo**
   - Consultas SQL desde BigQuery entre regiones o proyectos.
   - Materializaci√≥n de vistas para KPIs de alta demanda.
   - Dashboards en Looker / Data Studio con acceso controlado.

---

## 4. Servicios y Costos Estimados

| Servicio              | Rol en la Arquitectura | Estimaci√≥n Mensual (USD) |
|-----------------------|-------------------------|---------------------------|
| **Cloud Pub/Sub**     | Ingesta de eventos      | $10 ‚Äì $20                 |
| **Cloud Functions**   | Disparadores            | $5 ‚Äì $15                  |
| **Cloud Storage**     | 10 TB (landing/raw)     | $100 ‚Äì $150               |
| **CloudSQL**          | PostgreSQL regional     | $200 ‚Äì $500               |
| **Cloud Dataflow**    | Procesamiento diario    | $500 ‚Äì $1,200             |
| **BigQuery**          | 10 TB almacenados + 5 TB consultados | $400 ‚Äì $800 |
| **BigQuery Omni**     | Opcional (multi-cloud)  | $100 ‚Äì $300               |
| **Dataplex / Catalog**| Gobernanza, metadatos   | Sin costo directo         |
| **Looker / Studio**   | BI y dashboards         | Incluido (seg√∫n plan)     |

> ‚ö†Ô∏è Los costos var√≠an seg√∫n el volumen de datos, frecuencia de consulta, y ubicaci√≥n regional. Se recomienda aplicar pr√°cticas como **particionado, clustering y uso de vistas materializadas** para optimizar.

---

## 5. Gobernanza y Consistencia

- **Dataplex** se usar√° para definir zonas de datos: `raw`, `curated`, `analytics`.
- **Data Catalog** permite clasificar y versionar esquemas.
- Los pipelines incorporan validaci√≥n de esquema antes de cargar datos.
- Uso de JSON schemas versionados con Git para asegurar integridad en transformaciones.

---

## 6. Estrategias de Optimizaci√≥n

- **Vistas materializadas** para reducir consultas interregionales costosas.
- **BI Engine** para acelerar dashboards con cach√© en memoria.
- **Job scheduling** de agregaciones pesadas en horarios de baja demanda.
- **Dataflow autoscaling** para adaptarse al volumen din√°mico.

---

## 7. Riesgos y Mitigaciones

| Riesgo                        | Mitigaci√≥n                                   |
|------------------------------|----------------------------------------------|
| Latencia entre regiones      | Caching + vistas materializadas              |
| Cambios en esquemas fuente   | Validaci√≥n autom√°tica + versionado de esquema |
| Costos de escaneo elevado    | Particionado + Clustering + vistas agregadas |
| Fallos en pipelines          | Alertas + retries + DLQ con Pub/Sub          |

---

## 8. Recomendaciones

- Establecer un proyecto ‚Äúcore‚Äù para almacenamiento y consumo central.
- Aplicar IaC (Terraform) para replicabilidad y control de cambios.
- Establecer pr√°cticas DevOps/DataOps para despliegue y monitoreo.
- Monitorear adopci√≥n y calidad de datos con herramientas de lineage.

---

## 9. Conclusi√≥n

Esta arquitectura federada permite a la compa√±√≠a superar sus limitaciones actuales de integraci√≥n, disponibilidad y an√°lisis de datos. Gracias a servicios nativos de GCP, se logra una soluci√≥n moderna, segura, escalable y lista para habilitar tanto anal√≠tica descriptiva como casos de uso avanzados de inteligencia artificial y machine learning.

---

## 10. Repositorio y Entrega

El c√≥digo, diagramas y documentaci√≥n se encuentran en el siguiente repositorio p√∫blico:  
üîó [https://github.com/juanperez/latam-challenge](https://github.com/juanperez/latam-challenge)

Estructura recomendada del repositorio:

